watchlist           = watchlist,
feval               = evalerror,
maximize            = TRUE,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.6,
max_depth           = 6,
min_child_weight    = 200,
subsample           = 0.8,
colsample           = 0.67,
print.every.n       = 10
)
### Make predictions
validPreds <- as.data.frame(predict(clf, dtest, predleaf = TRUE))
names(validPreds) <- c(paste0('xgb_leaf_', 1:16))
head(validPreds)
setwd('/Users/ivanliu/Downloads/Prudential-Life-Insurance-Assessment')
# setwd('C:/Users/iliu2/Documents/Prudential-Life-Insurance-Assessment-master')
library(readr)
library(xgboost)
library(Metrics)
library(Hmisc)
library(caret)
# library(mlbench)
rm(list=ls());gc()
# load('data/fin_train_test_validation_prod.RData')
load('data/V_train_test_valid_xgb_meta_NEW.RData')
### Evaluation Func ###
evalerror = function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
err <- ScoreQuadraticWeightedKappa(as.numeric(labels),as.numeric(round(preds)))
return(list(metric = "kappa", value = err))
}
evalerror_2 = function(x = seq(1.5, 7.5, by = 1), preds, labels) {
cuts = c(min(preds), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(preds))
preds = as.numeric(Hmisc::cut2(preds, cuts))
err = Metrics::ScoreQuadraticWeightedKappa(as.numeric(labels), preds, 1, 8)
return(-err)
}
### Split Data ###
set.seed(23)
train <- rbind(train, validation)
cv <- 10
folds <- createFolds(as.factor(train$Response), k = cv, list = FALSE,)
dropitems <- c('Id','Response', paste0('xgb_meta_', 1:8))
feature.names <- names(train)[!names(train) %in% dropitems]
train_sc <- train
test_sc <- test
### Setup Results Table ###
results <- as.data.frame(matrix(rep(0,11*cv), cv))
names(results) <- c('cv_num', 'kappa', 'optim_kappa', 'fixed_kappa', '1st_cut', '2nd_cut',
'3rd_cut', '4th_cut', '5th_cut', '6th_cut', '7th_cut')
### Start Training ###
for(i in 1:cv){
f <- folds==i
dval          <- xgb.DMatrix(data=data.matrix(train_sc[f,feature.names]),label=train_sc[f,'Response'])
dtrain        <- xgb.DMatrix(data=data.matrix(train_sc[!f,feature.names]),label=train_sc[!f,'Response'])
watchlist     <- list(val=dval,train=dtrain)
clf <- xgb.train(data                = dtrain,
nrounds             = 16,
early.stop.round    = 200,
watchlist           = watchlist,
feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = TRUE,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.6,
max_depth           = 6,
min_child_weight    = 200,
subsample           = 0.8,
colsample           = 0.67,
print.every.n       = 1
)
### Make predictions
validPreds <- as.data.frame(predict(clf, dval, predleaf = TRUE))
names(validPreds) <- c(paste0('xgb_leaf_', 1:16))
train_sub <- cbind(Id = train_sc[f,'Id'], train_sc[f,feature.names], validPreds, Response = train_sc[f,'Response'])
if(i==1){
train_meta <- train_sub
}else{
train_meta <- rbind(train_meta, train_sub)
}
}
dtest          <- xgb.DMatrix(data=data.matrix(test_sc[,feature.names]),label=test_sc[,'Response']-1)
dtrain        <- xgb.DMatrix(data=data.matrix(train_sc[,feature.names]),label=train_sc[,'Response']-1)
watchlist     <- list(val=dtest,train=dtrain)
clf <- xgb.train(data                = dtrain,
nrounds             = 16,
early.stop.round    = 200,
watchlist           = watchlist,
feval               = evalerror,
maximize            = TRUE,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.6,
max_depth           = 6,
min_child_weight    = 200,
subsample           = 0.8,
colsample           = 0.67,
print.every.n       = 1
)
### Make predictions
validPreds <- as.data.frame(predict(clf, dtest, predleaf = TRUE))
names(validPreds) <- c(paste0('xgb_leaf_', 1:16))
test_meta <- cbind(Id = test_sc[,'Id'], test_sc[,feature.names], validPreds, Response = test_sc[,'Response'])
train <- train_meta
test <- test_meta
library(caret)
set.seed(1989)
head(train)
range(train$xgb_leaf_1)
range(test$xgb_leaf_1)
range(test$xgb_leaf_2)
range(train$xgb_leaf_2)
library(caret)
set.seed(1989)
# No validation
inTraining <- createDataPartition(train$Response, p = .5, list = FALSE)
train_a <- train[-inTraining,]
train_b <- train[inTraining,]
dim(train_b); dim(train_a); dim(test); dim(train)
save(train, train_b, train_a, test, file = 'data/VII_train_test_xgb_leaf.RData')
# Validation
inTraining <- createDataPartition(train$Response, p = .2, list = FALSE)
validation <- train[inTraining,]
# Train a & b
train <- train[-inTraining,]
inTraining <- createDataPartition(train$Response, p = .5, list = FALSE)
train_a <- train[-inTraining,]
train_b <- train[inTraining,]
dim(train_b); dim(train_a); dim(validation); dim(test); dim(train)
save(train, train_b, train_a, validation, test, file = 'data/fin_train_test_validation_xgb_leaf.RData')
head(test)
total_new <- rbind(train_meta, test_meta)
dummies <- dummyVars(Response ~ ., data = total_new[,c(paste0("xgb_leaf_", 1:16))], sep = "_", levelsOnly = FALSE, fullRank = TRUE)
c(paste0("xgb_leaf_", 1:16))
head(total_new[,paste0("xgb_leaf_", 1:16)])
for (col in paste0('xgb_leaf_',1:16)){
total_new[,col] <- as.factor(total_new[,col])
}
dummies <- dummyVars(Response ~ ., data = total_new[,paste0("xgb_leaf_", 1:16)], sep = "_", levelsOnly = FALSE, fullRank = TRUE)
dummies <- dummyVars(Response ~ ., data = total_new[,c(paste0("xgb_leaf_", 1:16), 'Response')],
sep = "_", levelsOnly = FALSE, fullRank = TRUE)
total1 <- as.data.frame(predict(dummies, newdata = total_new))
head(dummies)
head(total1)
dim(total1)
total_new <- cbind(total_new[,-c(ncol(total_new))], total1, Response=total_new$Response)
names(total_new)
train <- total_new[total_new$Response != 0, ]
test <- total_new[total_new$Response == 0, ]
library(caret)
set.seed(1989)
# No validation
inTraining <- createDataPartition(train$Response, p = .5, list = FALSE)
train_a <- train[-inTraining,]
train_b <- train[inTraining,]
dim(train_b); dim(train_a); dim(test); dim(train)
save(train, train_b, train_a, test, file = 'data/VII_train_test_xgb_leaf.RData')
# Validation
inTraining <- createDataPartition(train$Response, p = .2, list = FALSE)
validation <- train[inTraining,]
# Train a & b
train <- train[-inTraining,]
inTraining <- createDataPartition(train$Response, p = .5, list = FALSE)
train_a <- train[-inTraining,]
train_b <- train[inTraining,]
dim(train_b); dim(train_a); dim(validation); dim(test); dim(train)
save(train, train_b, train_a, validation, test, file = 'data/VII_train_test_validation_xgb_leaf.RData')
load('data/VII_train_test_validation_xgb_leaf.RData')
setwd('/Users/ivanliu/Downloads/Prudential-Life-Insurance-Assessment')
# setwd('C:/Users/iliu2/Documents/Prudential-Life-Insurance-Assessment-master')
library(readr)
library(xgboost)
library(Metrics)
library(Hmisc)
library(caret)
# library(mlbench)
rm(list=ls());gc()
# load('data/fin_train_test_validation_prod.RData')
# load('data/V_train_test_valid_xgb_meta_NEW.RData')
load('data/VII_train_test_validation_xgb_leaf.RData')
### Evaluation Func ###
evalerror = function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
err <- ScoreQuadraticWeightedKappa(as.numeric(labels),as.numeric(round(preds)))
return(list(metric = "kappa", value = err))
}
evalerror_2 = function(x = seq(1.5, 7.5, by = 1), preds, labels) {
cuts = c(min(preds), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(preds))
preds = as.numeric(Hmisc::cut2(preds, cuts))
err = Metrics::ScoreQuadraticWeightedKappa(as.numeric(labels), preds, 1, 8)
return(-err)
}
### Split Data ###
set.seed(23)
train <- rbind(train, validation)
cv <- 10
folds <- createFolds(as.factor(train$Response), k = cv, list = FALSE,)
dropitems <- c('Id','Response')#, paste0('TSNE_', 1:3), 'kmeans_all', 'Gender_Speci_feat')
feature.names <- names(train)[!names(train) %in% dropitems]
sc <- preProcess(train[,feature.names],method = c('center', 'scale'))
train_sc <- cbind(Id = train$Id, predict(sc, train[,feature.names]), Response = train$Response)
# train_sc <- train
### Setup Results Table ###
results <- as.data.frame(matrix(rep(0,11*cv), cv))
names(results) <- c('cv_num', 'kappa', 'optim_kappa', 'fixed_kappa', '1st_cut', '2nd_cut',
'3rd_cut', '4th_cut', '5th_cut', '6th_cut', '7th_cut')
### Start Training ###
for(i in 1:cv){
f <- folds==i
dval          <- xgb.DMatrix(data=data.matrix(train_sc[f,feature.names]),label=train_sc[f,'Response'])
dtrain        <- xgb.DMatrix(data=data.matrix(train_sc[!f,feature.names]),label=train_sc[!f,'Response'])
watchlist     <- list(val=dval,train=dtrain)
clf <- xgb.train(data                = dtrain,
nrounds             = 850,
early.stop.round    = 200,
watchlist           = watchlist,
feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = TRUE,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.035,
max_depth           = 6,
min_child_weight    = 100,
subsample           = 0.8,
colsample           = 0.7,
print.every.n       = 10
)
### Make predictions
validPreds <- predict(clf, dval)
kappa = evalerror_2(preds = validPreds, labels = train_sc[f,'Response'])
### Find optimal cutoff
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = validPreds, labels = train_sc[f,'Response'],
method = 'Nelder-Mead', control = list(maxit = 900000, trace = TRUE, REPORT = 500))
validPredsOptim = as.numeric(Hmisc::cut2(validPreds, c(-Inf, optCuts$par, Inf))); table(validPredsOptim)
optimal_kappa = evalerror_2(preds = validPredsOptim, labels = train_sc[f,'Response'])
fix_cut <- c(2.6121,	3.3566,	4.1097,	5.0359,	5.5267,	6.4481,	6.7450)
# avg: 2.7215,	3.5684,	4.0434,	4.8546,	5.4606,	6.2149,	6.7898
validPredsFix = as.numeric(Hmisc::cut2(validPreds, c(-Inf, fix_cut, Inf)));
fix_kappa = evalerror_2(preds = validPredsFix, labels = train_sc[f,'Response'])
results[i,1:11] <- c(paste0('CV_', i), -kappa, -optimal_kappa, -fix_kappa, optCuts$par)
View(results)
}
setwd('/Users/ivanliu/Downloads/Prudential-Life-Insurance-Assessment')
# setwd('C:/Users/iliu2/Documents/Prudential-Life-Insurance-Assessment-master')
library(readr)
library(xgboost)
library(Metrics)
library(Hmisc)
library(caret)
# library(mlbench)
rm(list=ls());gc()
# load('data/fin_train_test_validation_prod.RData')
# load('data/V_train_test_valid_xgb_meta_NEW.RData')
load('data/VII_train_test_validation_xgb_leaf.RData')
### Evaluation Func ###
evalerror = function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
err <- ScoreQuadraticWeightedKappa(as.numeric(labels),as.numeric(round(preds)))
return(list(metric = "kappa", value = err))
}
evalerror_2 = function(x = seq(1.5, 7.5, by = 1), preds, labels) {
cuts = c(min(preds), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(preds))
preds = as.numeric(Hmisc::cut2(preds, cuts))
err = Metrics::ScoreQuadraticWeightedKappa(as.numeric(labels), preds, 1, 8)
return(-err)
}
set.seed(23)
train <- rbind(train, validation)
cv <- 10
folds <- createFolds(as.factor(train$Response), k = cv, list = FALSE,)
dropitems <- c('Id','Response')#, paste0('TSNE_', 1:3), 'kmeans_all', 'Gender_Speci_feat')
feature.names <- names(train)[!names(train) %in% dropitems]
feature.names
feature.names
setwd('/Users/ivanliu/Downloads/Prudential-Life-Insurance-Assessment')
# setwd('C:/Users/iliu2/Documents/Prudential-Life-Insurance-Assessment-master')
library(readr)
library(xgboost)
library(Metrics)
library(Hmisc)
library(caret)
# library(mlbench)
rm(list=ls());gc()
# load('data/fin_train_test_validation_prod.RData')
load('data/V_train_test_valid_xgb_meta_NEW.RData')
### Evaluation Func ###
evalerror = function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
err <- ScoreQuadraticWeightedKappa(as.numeric(labels),as.numeric(round(preds)))
return(list(metric = "kappa", value = err))
}
evalerror_2 = function(x = seq(1.5, 7.5, by = 1), preds, labels) {
cuts = c(min(preds), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(preds))
preds = as.numeric(Hmisc::cut2(preds, cuts))
err = Metrics::ScoreQuadraticWeightedKappa(as.numeric(labels), preds, 1, 8)
return(-err)
}
### Split Data ###
set.seed(23)
train <- rbind(train, validation)
cv <- 10
folds <- createFolds(as.factor(train$Response), k = cv, list = FALSE,)
dropitems <- c('Id','Response', paste0('xgb_meta_', 1:8))
feature.names <- names(train)[!names(train) %in% dropitems]
train_sc <- train
test_sc <- test
### Setup Results Table ###
results <- as.data.frame(matrix(rep(0,11*cv), cv))
names(results) <- c('cv_num', 'kappa', 'optim_kappa', 'fixed_kappa', '1st_cut', '2nd_cut',
'3rd_cut', '4th_cut', '5th_cut', '6th_cut', '7th_cut')
feature.names
setwd('/Users/ivanliu/Downloads/Prudential-Life-Insurance-Assessment')
# setwd('C:/Users/iliu2/Documents/Prudential-Life-Insurance-Assessment-master')
library(readr)
library(xgboost)
library(Metrics)
library(Hmisc)
library(caret)
# library(mlbench)
rm(list=ls());gc()
# load('data/fin_train_test_validation_prod.RData')
load('data/V_train_test_valid_xgb_meta_NEW.RData')
### Evaluation Func ###
evalerror = function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
err <- ScoreQuadraticWeightedKappa(as.numeric(labels),as.numeric(round(preds)))
return(list(metric = "kappa", value = err))
}
evalerror_2 = function(x = seq(1.5, 7.5, by = 1), preds, labels) {
cuts = c(min(preds), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(preds))
preds = as.numeric(Hmisc::cut2(preds, cuts))
err = Metrics::ScoreQuadraticWeightedKappa(as.numeric(labels), preds, 1, 8)
return(-err)
}
### Split Data ###
set.seed(23)
train <- rbind(train, validation)
cv <- 10
folds <- createFolds(as.factor(train$Response), k = cv, list = FALSE,)
dropitems <- c('Id','Response', paste0('xgb_meta_', 1:8))
feature.names <- names(train)[!names(train) %in% dropitems]
train_sc <- train
test_sc <- test
### Setup Results Table ###
results <- as.data.frame(matrix(rep(0,11*cv), cv))
names(results) <- c('cv_num', 'kappa', 'optim_kappa', 'fixed_kappa', '1st_cut', '2nd_cut',
'3rd_cut', '4th_cut', '5th_cut', '6th_cut', '7th_cut')
### Start Training ###
for(i in 1:cv){
f <- folds==i
dval          <- xgb.DMatrix(data=data.matrix(train_sc[f,feature.names]),label=train_sc[f,'Response'])
dtrain        <- xgb.DMatrix(data=data.matrix(train_sc[!f,feature.names]),label=train_sc[!f,'Response'])
watchlist     <- list(val=dval,train=dtrain)
clf <- xgb.train(data                = dtrain,
nrounds             = 16,
early.stop.round    = 200,
watchlist           = watchlist,
feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = TRUE,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.6,
max_depth           = 6,
min_child_weight    = 200,
subsample           = 0.8,
colsample           = 0.67,
print.every.n       = 1
)
### Make predictions
validPreds <- as.data.frame(predict(clf, dval, predleaf = TRUE))
names(validPreds) <- c(paste0('xgb_leaf_', 1:16))
train_sub <- cbind(train_sc[f,-ncol(train_sc)], validPreds, Response = train_sc[f,'Response'])
if(i==1){
train_meta <- train_sub
}else{
train_meta <- rbind(train_meta, train_sub)
}
}
dtest          <- xgb.DMatrix(data=data.matrix(test_sc[,feature.names]),label=test_sc[,'Response']-1)
dtrain        <- xgb.DMatrix(data=data.matrix(train_sc[,feature.names]),label=train_sc[,'Response']-1)
watchlist     <- list(val=dtest,train=dtrain)
clf <- xgb.train(data                = dtrain,
nrounds             = 16,
early.stop.round    = 200,
watchlist           = watchlist,
feval               = evalerror,
maximize            = TRUE,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.6,
max_depth           = 6,
min_child_weight    = 200,
subsample           = 0.8,
colsample           = 0.67,
print.every.n       = 1
)
### Make predictions
validPreds <- as.data.frame(predict(clf, dtest, predleaf = TRUE))
names(validPreds) <- c(paste0('xgb_leaf_', 1:16))
test_meta <- cbind(test_sc[,-ncol(test_sc)], validPreds, Response = test_sc[,'Response'])
total_new <- rbind(train_meta, test_meta)
for (col in paste0('xgb_leaf_',1:16)){
total_new[,col] <- as.factor(total_new[,col])
}
dummies <- dummyVars(Response ~ ., data = total_new[,c(paste0("xgb_leaf_", 1:16), 'Response')],
sep = "_", levelsOnly = FALSE, fullRank = TRUE)
total1 <- as.data.frame(predict(dummies, newdata = total_new))
total_new <- cbind(total_new[,-c(ncol(total_new))], total1, Response=total_new$Response)
train <- total_new[total_new$Response != 0, ]
test <- total_new[total_new$Response == 0, ]
library(caret)
set.seed(1989)
dim(train_b); dim(train_a); dim(test); dim(train)
地面（
dim(test)
names(test)
save(train, test, file = 'data/VII_train_test_xgb_leaf.RData')
setwd('/Users/ivanliu/Downloads/Prudential-Life-Insurance-Assessment')
# setwd('C:/Users/iliu2/Documents/Prudential-Life-Insurance-Assessment-master')
library(readr)
library(xgboost)
library(Metrics)
library(Hmisc)
library(caret)
# library(mlbench)
rm(list=ls());gc()
# load('data/fin_train_test_validation_prod.RData')
# load('data/V_train_test_valid_xgb_meta_NEW.RData')
load('data/VII_train_test_xgb_leaf.RData')
setwd('/Users/ivanliu/Downloads/Prudential-Life-Insurance-Assessment')
# setwd('C:/Users/iliu2/Documents/Prudential-Life-Insurance-Assessment-master')
library(readr)
library(xgboost)
library(Metrics)
library(Hmisc)
library(caret)
# library(mlbench)
rm(list=ls());gc()
# load('data/fin_train_test_validation_prod.RData')
# load('data/V_train_test_valid_xgb_meta_NEW.RData')
load('data/VII_train_test_xgb_leaf.RData')
### Evaluation Func ###
evalerror = function(preds, dtrain) {
labels <- getinfo(dtrain, "label")
err <- ScoreQuadraticWeightedKappa(as.numeric(labels),as.numeric(round(preds)))
return(list(metric = "kappa", value = err))
}
evalerror_2 = function(x = seq(1.5, 7.5, by = 1), preds, labels) {
cuts = c(min(preds), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(preds))
preds = as.numeric(Hmisc::cut2(preds, cuts))
err = Metrics::ScoreQuadraticWeightedKappa(as.numeric(labels), preds, 1, 8)
return(-err)
}
### Split Data ###
set.seed(23)
cv <- 10
folds <- createFolds(as.factor(train$Response), k = cv, list = FALSE,)
dropitems <- c('Id','Response')#, paste0('TSNE_', 1:3), 'kmeans_all', 'Gender_Speci_feat')
feature.names <- names(train)[!names(train) %in% dropitems]
sc <- preProcess(train[,feature.names],method = c('center', 'scale'))
train_sc <- cbind(Id = train$Id, predict(sc, train[,feature.names]), Response = train$Response)
# train_sc <- train
results <- as.data.frame(matrix(rep(0,11*cv), cv))
feature.names
feature.names <- names(train)[!names(train) %in% dropitems]
train_sc <- cbind(Id = train$Id, predict(sc, train[,feature.names]), Response = train$Response)
# train_sc <- train
train_sc <- train
results <- as.data.frame(matrix(rep(0,11*cv), cv))
names(results) <- c('cv_num', 'kappa', 'optim_kappa', 'fixed_kappa', '1st_cut', '2nd_cut',
'3rd_cut', '4th_cut', '5th_cut', '6th_cut', '7th_cut')
for(i in 1:cv){
f <- folds==i
dval          <- xgb.DMatrix(data=data.matrix(train_sc[f,feature.names]),label=train_sc[f,'Response'])
dtrain        <- xgb.DMatrix(data=data.matrix(train_sc[!f,feature.names]),label=train_sc[!f,'Response'])
watchlist     <- list(val=dval,train=dtrain)
clf <- xgb.train(data                = dtrain,
nrounds             = 850,
early.stop.round    = 200,
watchlist           = watchlist,
feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = TRUE,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.035,
max_depth           = 6,
min_child_weight    = 100,
subsample           = 0.8,
colsample           = 0.7,
print.every.n       = 10
)
### Make predictions
validPreds <- predict(clf, dval)
kappa = evalerror_2(preds = validPreds, labels = train_sc[f,'Response'])
### Find optimal cutoff
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = validPreds, labels = train_sc[f,'Response'],
method = 'Nelder-Mead', control = list(maxit = 900000, trace = TRUE, REPORT = 500))
validPredsOptim = as.numeric(Hmisc::cut2(validPreds, c(-Inf, optCuts$par, Inf))); table(validPredsOptim)
optimal_kappa = evalerror_2(preds = validPredsOptim, labels = train_sc[f,'Response'])
fix_cut <- c(2.6121,	3.3566,	4.1097,	5.0359,	5.5267,	6.4481,	6.7450)
# avg: 2.7215,	3.5684,	4.0434,	4.8546,	5.4606,	6.2149,	6.7898
validPredsFix = as.numeric(Hmisc::cut2(validPreds, c(-Inf, fix_cut, Inf)));
fix_kappa = evalerror_2(preds = validPredsFix, labels = train_sc[f,'Response'])
results[i,1:11] <- c(paste0('CV_', i), -kappa, -optimal_kappa, -fix_kappa, optCuts$par)
View(results)
}
