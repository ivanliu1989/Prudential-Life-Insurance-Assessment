dropitems <- c('Id','Response'#'Medical_History_10','Medical_History_24',
# 'Cnt_NA_Emp_row','Cnt_NA_Fam_row','Cnt_NA_Medi_row','Cnt_NA_Ins_row'
# 'Gender_Speci_feat'
, 'TSNE_1', 'TSNE_2', 'TSNE_3', 'KMEANS'
)
feature.names <- names(train)[!names(train) %in% dropitems]
dval          <- xgb.DMatrix(data=data.matrix(validation[,feature.names]),label=validation$Response)
dtrain        <- xgb.DMatrix(data=data.matrix(train[,feature.names]),label=train$Response)
dtrain_a      <- xgb.DMatrix(data=data.matrix(train_a[,feature.names]),label=train_a$Response)
dtrain_b      <- xgb.DMatrix(data=data.matrix(train_b[,feature.names]),label=train_b$Response)
dtest         <- xgb.DMatrix(data=data.matrix(test[,feature.names]),label=test$Response)
watchlist     <- list(val=dval,train=dtrain)
watchlist_ab  <- list(val=dtrain_b,train=dtrain_a)
watchlist_ba  <- list(val=dtrain_a,train=dtrain_b)
clf <- xgb.train(data                = dtrain, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = TRUE,
verbose             = 1,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
)
### Make predictions
validPreds <- predict(clf, data.matrix(validation[,feature.names]))
validScore <- ScoreQuadraticWeightedKappa(round(validPreds),validation$Response)
evalerror_2(preds = validPreds, labels = validation$Response)
### Find optimal cutoff
library(mlr)
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = validPreds, labels = validation$Response,
method = 'Nelder-Mead', control = list(maxit = 30000, trace = TRUE, REPORT = 500))
optCuts
validPredsOptim = as.numeric(Hmisc::cut2(validPreds, c(-Inf, optCuts$par, Inf))); table(validPredsOptim)
evalerror_2(preds = validPredsOptim, labels = validation$Response)
validPreds_kappa <- validPreds
clf <- xgb.train(data                = dtrain, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
)
### Make predictions
validPreds <- predict(clf, data.matrix(validation[,feature.names]))
validScore <- ScoreQuadraticWeightedKappa(round(validPreds),validation$Response)
evalerror_2(preds = validPreds, labels = validation$Response)
### Find optimal cutoff
library(mlr)
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = validPreds, labels = validation$Response,
method = 'Nelder-Mead', control = list(maxit = 30000, trace = TRUE, REPORT = 500))
optCuts
validPredsOptim = as.numeric(Hmisc::cut2(validPreds, c(-Inf, optCuts$par, Inf))); table(validPredsOptim)
evalerror_2(preds = validPredsOptim, labels = validation$Response)
# VALIDATION-TRAIN: 0.6143617/0.6602325
# 0.6128556/0.6553111 tsne
# 0.6129287/0.6553886 no tsne
# 0.6147117/0.657316 raw kappa with tsne kmeans
# 0.6140779/0.6557817 raw kappa with no tsne kmeans
validPreds_rsme <- validPreds
validPreds_kappa
validPreds_rsme
validPreds_objectives <- (validPreds_kappa + validPreds_rsme)/2
validPreds_objectives
validPreds <- (validPreds_kappa + validPreds_rsme)/2
validScore <- ScoreQuadraticWeightedKappa(round(validPreds),validation$Response)
evalerror_2(preds = validPreds, labels = validation$Response)
### Find optimal cutoff
library(mlr)
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = validPreds, labels = validation$Response,
method = 'Nelder-Mead', control = list(maxit = 30000, trace = TRUE, REPORT = 500))
optCuts
validPredsOptim = as.numeric(Hmisc::cut2(validPreds, c(-Inf, optCuts$par, Inf))); table(validPredsOptim)
evalerror_2(preds = validPredsOptim, labels = validation$Response)
setwd('/Users/ivanliu/Downloads/Prudential-Life-Insurance-Assessment')
library(readr)
library(xgboost)
library(Metrics)
library(Hmisc)
rm(list=ls());gc()
##############################
# 1. Read Data #####
####################
load('data/fin_train_test_validation.RData')
# load('data/fin_train_test.RData')
# load('data/fin_train_test_validation_onehot.RData')
##############################
# 2. Eval Func #####
####################
evalerror = function(preds, dtrain) {
#     x = seq(1.5, 7.5, by = 1)
#     labels <- getinfo(dtrain, "label")
#     cuts = c(min(preds), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(preds))
#     preds = as.numeric(Hmisc::cut2(preds, cuts))
#     err = Metrics::ScoreQuadraticWeightedKappa(as.numeric(labels), preds, 1, 8)
#     return(list(metric = "kappa", value = err))
labels <- getinfo(dtrain, "label")
err <- ScoreQuadraticWeightedKappa(as.numeric(labels),as.numeric(round(preds)))
return(list(metric = "kappa", value = err))
}
evalerror_2 = function(x = seq(1.5, 7.5, by = 1), preds, labels) {
cuts = c(min(preds), x[1], x[2], x[3], x[4], x[5], x[6], x[7], max(preds))
preds = as.numeric(Hmisc::cut2(preds, cuts))
err = Metrics::ScoreQuadraticWeightedKappa(as.numeric(labels), preds, 1, 8)
return(-err)
}
#####################################
# 3. Model strategies #####
###########################
# 1. split the training data into two parts: A and B.
# Train on part A and then predict on part B. Train on part B and then predict on part A.
# Combine the predictions on A and B.
# Use optim to get cutpoints based on the true training labels and your predictions
set.seed(23)
dropitems <- c('Id','Response'#'Medical_History_10','Medical_History_24',
# 'Cnt_NA_Emp_row','Cnt_NA_Fam_row','Cnt_NA_Medi_row','Cnt_NA_Ins_row'
# 'Gender_Speci_feat'
# , 'TSNE_1', 'TSNE_2', 'TSNE_3', 'KMEANS'
)
feature.names <- names(train)[!names(train) %in% dropitems]
dval          <- xgb.DMatrix(data=data.matrix(validation[,feature.names]),label=validation$Response)
dtrain        <- xgb.DMatrix(data=data.matrix(train[,feature.names]),label=train$Response)
dtrain_a      <- xgb.DMatrix(data=data.matrix(train_a[,feature.names]),label=train_a$Response)
dtrain_b      <- xgb.DMatrix(data=data.matrix(train_b[,feature.names]),label=train_b$Response)
dtest         <- xgb.DMatrix(data=data.matrix(test[,feature.names]),label=test$Response)
watchlist     <- list(val=dval,train=dtrain)
watchlist_ab  <- list(val=dtrain_b,train=dtrain_a)
watchlist_ba  <- list(val=dtrain_a,train=dtrain_b)
clf <- xgb.train(data                = dtrain_a, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_ab, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
)
### Make predictions
validPreds <- predict(clf, data.matrix(validation[,feature.names]))
validScore <- ScoreQuadraticWeightedKappa(round(validPreds),validation$Response)
evalerror_2(preds = validPreds, labels = validation$Response)
### Find optimal cutoff
library(mlr)
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = validPreds, labels = validation$Response,
method = 'Nelder-Mead', control = list(maxit = 30000, trace = TRUE, REPORT = 500))
optCuts
validPredsOptim = as.numeric(Hmisc::cut2(validPreds, c(-Inf, optCuts$par, Inf))); table(validPredsOptim)
evalerror_2(preds = validPredsOptim, labels = validation$Response)
pred_b <- predict(clf, data.matrix(train_b[,feature.names]))
evalerror_2(preds = pred_b, labels = train_b$Response)
clf <- xgb.train(data                = dtrain_b, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_ba, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
)
pred_a <- predict(clf, data.matrix(train_a[,feature.names]))
evalerror_2(preds = pred_a, labels = train_a$Response)
trainPred <- c(pred_a, pred_b); trainLabel <- c(train_a$Response, train_b$Response)
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = trainPred, labels = trainLabel,
method = 'Nelder-Mead', control = list(maxit = 30000, trace = TRUE, REPORT = 500))
trainPredsOptim = as.numeric(Hmisc::cut2(trainPred, c(-Inf, optCuts$par, Inf))); table(trainPredsOptim)
evalerror_2(preds = trainPredsOptim, labels = trainLabel)
head(trainPred)
train_2nd <- rbind(train_a, train_b)
train_2nd$META_XGB_RMSE <- trainPred
clf <- xgb.train(data                = dtrain_a, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_ab, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = T,
verbose             = 1,
objective           = "reg:linear",
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
)
pred_b <- predict(clf, data.matrix(train_b[,feature.names]))
evalerror_2(preds = pred_b, labels = train_b$Response)
clf <- xgb.train(data                = dtrain_b, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_ba, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = T,
verbose             = 1,
objective           = "reg:linear",  # multi:softmax, reg:linear
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
)
pred_a <- predict(clf, data.matrix(train_a[,feature.names]))
evalerror_2(preds = pred_a, labels = train_a$Response)
trainPred <- c(pred_a, pred_b); trainLabel <- c(train_a$Response, train_b$Response)
train_2nd$META_XGB_KAPPA <- trainPred
?xgb.train
clf <- xgb.train(data                = dtrain_a, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_ab, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "multi:softprob",  # multi:softmax, reg:linear, multi:softprob
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
)
clf <- xgb.train(data                = dtrain_a, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_ab, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "multi:softprob",  # multi:softmax, reg:linear, multi:softprob
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
,num_class = 8
)
validation$Response
dval          <- xgb.DMatrix(data=data.matrix(validation[,feature.names]),label=validation$Response-1)
dtrain        <- xgb.DMatrix(data=data.matrix(train[,feature.names]),label=train$Response-1)
dtrain_a      <- xgb.DMatrix(data=data.matrix(train_a[,feature.names]),label=train_a$Response-1)
dtrain_b      <- xgb.DMatrix(data=data.matrix(train_b[,feature.names]),label=train_b$Response-1)
dtest         <- xgb.DMatrix(data=data.matrix(test[,feature.names]),label=test$Response-1)
watchlist     <- list(val=dval,train=dtrain)
watchlist_ab  <- list(val=dtrain_b,train=dtrain_a)
watchlist_ba  <- list(val=dtrain_a,train=dtrain_b)
clf <- xgb.train(data                = dtrain_a, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_ab, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "multi:softprob",  # multi:softmax, reg:linear, multi:softprob
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
,num_class = 8
)
pred_b <- predict(clf, data.matrix(train_b[,feature.names]))
head(pred_b)
dim(pred_b)
length(pred_b)
head(matrix(pred_b, ncol=8))
dim(matrix(pred_b, ncol=8))
dim(train_a)
clf <- xgb.train(data                = dtrain_b, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_ba, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "multi:softprob",  # multi:softmax, reg:linear, multi:softprob
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
,num_class = 8
)
paste('META_XGB_MUL_', 1:8)
pred_a <- predict(clf, data.matrix(train_a[,feature.names]))
META_XGB_MULSOFT <- as.data.frame(rbind(matrix(pred_a, ncol=8), matrix(pred_b, ncol=8)))
names(META_XGB_MULSOFT) <- paste('META_XGB_MUL_', 1:8, sep = '')
dim(META_XGB_MULSOFT)
head(META_XGB_MULSOFT)
dim(pred_b)
dim(matrix(pred_a, ncol=8))
dim(train)
train_2nd <- cbind(train_2nd, META_XGB_MULSOFT)
feature.names.stack <- names(train_2nd)[!names(train_2nd) %in% dropitems]
dtrain_stack <- xgb.DMatrix(data=data.matrix(train_2nd[,feature.names.stack]),label=train_2nd$Response)
feature.names.stack
clf <- xgb.train(data                = dtrain, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "multi:softprob",  # multi:softmax, reg:linear, multi:softprob
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
,num_class = 8
)
### Make predictions
validPreds <- predict(clf, data.matrix(validation[,feature.names]))
META_XGB_MULSOFT <- as.data.frame(matrix(validPreds, ncol=8)); names(META_XGB_MULSOFT) <- paste('META_XGB_MUL_', 1:8, sep = '')
META_XGB_MULSOFT
validPreds <- predict(clf, data.matrix(validation[,feature.names]))
length(validPreds)
dim(validation)
META_XGB_MULSOFT <- as.data.frame(matrix(validPreds, ncol=8)); names(META_XGB_MULSOFT) <- paste('META_XGB_MUL_', 1:8, sep = '')
feature.names <- names(train)[!names(train) %in% dropitems]
dval          <- xgb.DMatrix(data=data.matrix(validation[,feature.names]),label=validation$Response) #-1
dtrain        <- xgb.DMatrix(data=data.matrix(train[,feature.names]),label=train$Response)
dtrain_a      <- xgb.DMatrix(data=data.matrix(train_a[,feature.names]),label=train_a$Response)
dtrain_b      <- xgb.DMatrix(data=data.matrix(train_b[,feature.names]),label=train_b$Response)
dtest         <- xgb.DMatrix(data=data.matrix(test[,feature.names]),label=test$Response)
watchlist     <- list(val=dval,train=dtrain)
watchlist_ab  <- list(val=dtrain_b,train=dtrain_a)
watchlist_ba  <- list(val=dtrain_a,train=dtrain_b)
clf <- xgb.train(data                = dtrain, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "reg:linear",  # multi:softmax, reg:linear, multi:softprob
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
# ,num_class = 8
)
### Make predictions
validPreds <- predict(clf, data.matrix(validation[,feature.names]))
validation$META_XGB_RMSE <- validPreds
clf <- xgb.train(data                = dtrain, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = T,
verbose             = 1,
objective           = "reg:linear",  # multi:softmax, reg:linear, multi:softprob
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
# ,num_class = 8
)
### Make predictions
validPreds <- predict(clf, data.matrix(validation[,feature.names]))
validation$META_XGB_KAPPA <- validPreds
dval_stack <- xgb.DMatrix(data=data.matrix(validation[,feature.names.stack]),label=validation$Response)
validation <- cbind(validation, META_XGB_MULSOFT)
dval_stack <- xgb.DMatrix(data=data.matrix(validation[,feature.names.stack]),label=validation$Response)
watchlist_stack <- list(val=dval_stack,train=dtrain_stack)
clf <- xgb.train(data                = dtrain_stack, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_stack, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
feval               = evalerror,
# eval_metric         = 'rmse',
maximize            = T,
verbose             = 1,
objective           = "reg:linear",  # multi:softmax, reg:linear, multi:softprob
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
# ,num_class = 8
)
validPreds <- predict(clf, data.matrix(validation[,feature.names]))
validScore <- ScoreQuadraticWeightedKappa(round(validPreds),validation$Response)
validScore
evalerror_2(preds = validPreds, labels = validation$Response)
validPreds <- predict(clf, data.matrix(validation[,feature.names.stack]))
validScore <- ScoreQuadraticWeightedKappa(round(validPreds),validation$Response)
evalerror_2(preds = validPreds, labels = validation$Response)
validScore
library(mlr)
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = validPreds, labels = validation$Response,
method = 'Nelder-Mead', control = list(maxit = 30000, trace = TRUE, REPORT = 500))
optCuts
validPredsOptim = as.numeric(Hmisc::cut2(validPreds, c(-Inf, optCuts$par, Inf))); table(validPredsOptim)
evalerror_2(preds = validPredsOptim, labels = validation$Response)
validPreds_rsme <- validPreds
validPreds_kappa <- validPreds
clf <- xgb.train(data                = dtrain_stack, # dtrain_a, dtrain_b, dtrain, dtrain_stack
nrounds             = 800,
early.stop.round    = 200,
watchlist           = watchlist_stack, # watchlist_ab, watchlist_ba, watchlist, watchlist_stack
# feval               = evalerror,
eval_metric         = 'rmse',
maximize            = F,
verbose             = 1,
objective           = "reg:linear",  # multi:softmax, reg:linear, multi:softprob
booster             = "gbtree",
eta                 = 0.035,
# gamma               = 0.05,
max_depth           = 6,
min_child_weight    = 3,
subsample           = 0.9,
colsample           = 0.67,
print.every.n       = 10
# ,num_class = 8
)
### Make predictions
validPreds <- predict(clf, data.matrix(validation[,feature.names.stack]))  # feature.names.stack
validScore <- ScoreQuadraticWeightedKappa(round(validPreds),validation$Response)
evalerror_2(preds = validPreds, labels = validation$Response)
### Find optimal cutoff
library(mlr)
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = validPreds, labels = validation$Response,
method = 'Nelder-Mead', control = list(maxit = 30000, trace = TRUE, REPORT = 500))
optCuts
validPredsOptim = as.numeric(Hmisc::cut2(validPreds, c(-Inf, optCuts$par, Inf))); table(validPredsOptim)
evalerror_2(preds = validPredsOptim, labels = validation$Response)
validPreds_rsme <- validPreds
validPreds <- (validPreds_kappa + validPreds_rsme)/2
validScore <- ScoreQuadraticWeightedKappa(round(validPreds),validation$Response)
evalerror_2(preds = validPreds, labels = validation$Response)
library(mlr)
optCuts = optim(seq(1.5, 7.5, by = 1), evalerror_2, preds = validPreds, labels = validation$Response,
method = 'Nelder-Mead', control = list(maxit = 30000, trace = TRUE, REPORT = 500))
optCuts
validPredsOptim = as.numeric(Hmisc::cut2(validPreds, c(-Inf, optCuts$par, Inf))); table(validPredsOptim)
evalerror_2(preds = validPredsOptim, labels = validation$Response)
